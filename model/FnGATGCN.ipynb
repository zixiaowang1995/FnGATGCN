{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "from torch import Tensor   \n",
    "import torch_geometric\n",
    "from torch_geometric.nn import GCNConv, GATConv, GINConv, global_add_pool\n",
    "from torch_geometric.data import Data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import NNConv, MessagePassing\n",
    "from torch.nn import Linear, CrossEntropyLoss, Sequential, ReLU, BCELoss \n",
    "import torch_geometric.transforms as T\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.nn import global_mean_pool as gap,  global_max_pool as gmp, global_add_pool as gsp\n",
    "import torch.nn as nn\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "from rdkit import Chem                      \n",
    "from rdkit.Chem import GetAdjacencyMatrix       \n",
    "from scipy.sparse import coo_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import Chem, DataStructs\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "from random import shuffle\n",
    "\n",
    "import re\n",
    "import gensim\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch_geometric\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "generator = torch.Generator(device=device)\n",
    "\n",
    "torch.manual_seed(8) \n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onek_encoding_unk(value, choices):\n",
    "    \"\"\"\n",
    "    Creates a one-hot encoding with an extra category for uncommon values.\n",
    "\n",
    "    :param value: The value for which the encoding should be one.\n",
    "    :param choices: A list of possible values.\n",
    "    :return: A one-hot encoding of the :code:`value` in a list of length :code:`len(choices) + 1`.\n",
    "             If :code:`value` is not in :code:`choices`, then the final element in the encoding is -1.\n",
    "    \"\"\"\n",
    "    encoding = [0] * (len(choices) + 1)\n",
    "    index = choices.index(value) if value in choices else -1\n",
    "    encoding[index] = 1\n",
    "\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atom_features(atom,\n",
    "                  bool_id_feat=False,\n",
    "                  explicit_H=False,\n",
    "                  use_chirality=True):\n",
    "    if bool_id_feat:\n",
    "        return [atom_to_id(atom)]\n",
    "    else:\n",
    "        results = onek_encoding_unk(\n",
    "          atom.GetSymbol(),\n",
    "          [\n",
    "            'B',\n",
    "            'C',\n",
    "            'N',\n",
    "            'O',\n",
    "            'F',\n",
    "            'Si',\n",
    "            'P',\n",
    "            'S',\n",
    "            'Cl',\n",
    "            'As',\n",
    "            'Se',\n",
    "            'Br',\n",
    "            'Te',\n",
    "            'I',\n",
    "            'At',\n",
    "            'other'\n",
    "          ]) + onek_encoding_unk(atom.GetDegree(),\n",
    "                                 [0, 1, 2, 3, 4, 5]) + \\\n",
    "                  [atom.GetFormalCharge(), atom.GetNumRadicalElectrons()] + \\\n",
    "                  onek_encoding_unk(atom.GetHybridization(), [\n",
    "                    Chem.rdchem.HybridizationType.SP, Chem.rdchem.HybridizationType.SP2,\n",
    "                    Chem.rdchem.HybridizationType.SP3, Chem.rdchem.HybridizationType.\n",
    "                                        SP3D, Chem.rdchem.HybridizationType.SP3D2,'other'\n",
    "                  ]) + [atom.GetIsAromatic()]\n",
    "        # In case of explicit hydrogen(QM8, QM9), avoid calling `GetTotalNumHs`\n",
    "        if not explicit_H:\n",
    "            results = results + onek_encoding_unk(atom.GetTotalNumHs(),\n",
    "                                                      [0, 1, 2, 3, 4])\n",
    "        if use_chirality:\n",
    "            try:\n",
    "                results = results + onek_encoding_unk(\n",
    "                    atom.GetProp('_CIPCode'),\n",
    "                    ['R', 'S']) + [atom.HasProp('_ChiralityPossible')]\n",
    "            except:\n",
    "                results = results + [0, 0, 0\n",
    "                                     ] + [atom.HasProp('_ChiralityPossible')]\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "def bond_features(bond: Chem.rdchem.Bond):\n",
    "    \"\"\"\n",
    "    Builds a feature vector for a bond.\n",
    "\n",
    "    :param bond: An RDKit bond.\n",
    "    :return: A list containing the bond features.\n",
    "    \"\"\"\n",
    "    if bond is None:\n",
    "        fbond = [1] + [0] * (14 - 1)\n",
    "    else:\n",
    "        bt = bond.GetBondType()\n",
    "        fbond = [\n",
    "            0,  # bond is not None\n",
    "            bt == Chem.rdchem.BondType.SINGLE,\n",
    "            bt == Chem.rdchem.BondType.DOUBLE,\n",
    "            bt == Chem.rdchem.BondType.TRIPLE,\n",
    "            bt == Chem.rdchem.BondType.AROMATIC,\n",
    "            (bond.GetIsConjugated() if bt is not None else 0),\n",
    "            (bond.IsInRing() if bt is not None else 0)\n",
    "        ]\n",
    "        fbond += onek_encoding_unk(int(bond.GetStereo()), list(range(6)))\n",
    "    return fbond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MORGAN_RADIUS = 2\n",
    "MORGAN_NUM_BITS = 1024\n",
    "#a vector representation (1x2048) for molecular feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def morgan_binary_features_generator(mol,\n",
    "                                     radius: int = MORGAN_RADIUS,\n",
    "                                     num_bits: int = MORGAN_NUM_BITS):\n",
    "    \"\"\"\n",
    "    Generates a binary Morgan fingerprint for a molecule.\n",
    "    :param mol: A molecule (i.e., either a SMILES or an RDKit molecule).\n",
    "    :param radius: Morgan fingerprint radius.\n",
    "    :param num_bits: Number of bits in Morgan fingerprint.\n",
    "    :return: A 1D numpy array containing the binary Morgan fingerprint.\n",
    "    \"\"\"\n",
    "    mol = Chem.MolFromSmiles(mol) if type(mol) == str else mol\n",
    "    features_vec = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=num_bits)\n",
    "    features = np.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(features_vec, features)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(dataset,batch_size):\n",
    "    SMILES = dataset['SMILES']\n",
    "    data_list = []\n",
    "    \n",
    "    for smiles in SMILES:\n",
    "            \n",
    "        mol = Chem.MolFromSmiles(smiles)     \n",
    "\n",
    "        #generate a global vector features (binary Morgan fingerprint) and convert them\n",
    "        mol_feature = torch.tensor(morgan_binary_features_generator(mol))\n",
    "\n",
    "        xs = []\n",
    "        for atom in mol.GetAtoms():\n",
    "            x = atom_features(atom)\n",
    "            xs.append(x)\n",
    "            \n",
    "        x = torch.tensor(xs)\n",
    "        \n",
    "        edge_indices, edge_attrs = [], []\n",
    "        \n",
    "        for bond in mol.GetBonds():\n",
    "            i = bond.GetBeginAtomIdx()\n",
    "            j = bond.GetEndAtomIdx()\n",
    "    \n",
    "            e = bond_features(bond)\n",
    "\n",
    "            edge_indices += [[i,j],[j,i]]\n",
    "            edge_attrs += [e, e]\n",
    "        \n",
    "        edge_index = torch.tensor(edge_indices)\n",
    "        edge_index = edge_index.t().to(torch.long).view(2, -1)\n",
    "        edge_attr = torch.tensor(edge_attrs).view(-1, 14)\n",
    "        \n",
    "        y = torch.tensor(int(dataset.loc[dataset['SMILES'] == smiles, 'Activity'].values[0])) #response variable y\n",
    "\n",
    "        smi = smiles\n",
    "\n",
    "        # add smiles and num_feature as the attributes\n",
    "        data = Data(x=x, y=y, edge_index=edge_index, edge_attr = edge_attr, smiles=smi, mol_feature=mol_feature)  \n",
    "        data_list.append(data)   # store processed data into the list\n",
    "        \n",
    "    return DataLoader(data_list, batch_size, shuffle=True,generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weights(m):\n",
    "  '''\n",
    "    Try resetting model weights to avoid\n",
    "    weight leakage.\n",
    "  '''\n",
    "  for layer in m.children():\n",
    "    if hasattr(layer, 'reset_parameters'):\n",
    "        print(f'Reset trainable parameters of layer = {layer}')\n",
    "        layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch,train_loader):\n",
    "    \n",
    "    model.train()   \n",
    "    running_loss = 0 \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    criterion = BCELoss()\n",
    "    y_val=[]\n",
    "    y_pred=[]\n",
    "    for batch in train_loader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch)\n",
    "        label = batch.y.view(-1,1)\n",
    "        loss = criterion(outputs.float(),label.float())\n",
    "        \n",
    "\n",
    "        loss.backward()   # Compute the gradient of loss function \n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        running_loss += loss.item()\n",
    "        # probability that is larger than 0.5, classify as 1 \n",
    "\n",
    "        pred = (outputs >= 0.5).float()\n",
    "\n",
    "        total += label.size(0)\n",
    "        correct += (pred == label).float().sum()\n",
    "        \n",
    "        y_val.extend(label.cpu().tolist())\n",
    "        y_pred.extend(outputs.cpu().tolist())\n",
    "\n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "    loss = running_loss/len(train_loader)\n",
    "    accuracy = 100*correct/total\n",
    "    train_auc.append(auc) \n",
    "    train_accuracy.append(accuracy)\n",
    "    train_loss.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch,test_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y_val=[]\n",
    "    y_pred=[]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        criterion = BCELoss()\n",
    "        for batch in test_loader:\n",
    "        \n",
    "            outputs = model(batch)\n",
    "            label = batch.y.view(-1,1)\n",
    "\n",
    "            loss = criterion(outputs.float(), label.float())    \n",
    "            running_loss += loss.item()\n",
    "            # probability that is larger than 0.5, classify as 1 \n",
    "            pred = (outputs >= 0.5).float()\n",
    "\n",
    "            total += label.size(0)\n",
    "            correct += (pred == label).float().sum()\n",
    "            y_val.extend(label.cpu().tolist())\n",
    "            y_pred.extend(outputs.cpu().tolist())\n",
    "        auc = roc_auc_score(y_val, y_pred)\n",
    "        loss = running_loss/len(test_loader)\n",
    "        accuracy = 100*correct/total\n",
    "    \n",
    "        test_accuracy.append(accuracy)\n",
    "        test_loss.append(loss)\n",
    "        test_auc.append(auc) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_set as a whole loader\n",
    "def test_metrics(test_loader):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        labels = []\n",
    "        preds = []\n",
    "        for batch in test_loader:\n",
    "            \n",
    "            labels += list(batch.y.view(-1, 1).cpu().numpy())\n",
    "            preds += list(model(batch).detach().cpu().numpy())\n",
    "        \n",
    "        pred_labels = [1 if i > 0.5 else 0 for i in preds]\n",
    "        auc = roc_auc_score(list(labels), list(preds))\n",
    "        report = classification_report(labels, pred_labels,output_dict=True)\n",
    "        return auc, report\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FnGATGCN(torch.nn.Module):\n",
    "    def __init__(self, num_features_xd=44, n_output=1,output_dim=50, dropout=0.1):\n",
    "        super(FnGATGCN, self).__init__()\n",
    "\n",
    "        # graph layers\n",
    "        self.conv1 = GATConv(num_features_xd, num_features_xd, heads=10)\n",
    "        self.conv2 = GCNConv(num_features_xd*10, num_features_xd*10)\n",
    "        self.fc_g1 = torch.nn.Linear(num_features_xd*10*2,1500)\n",
    "        self.fc_g2 = torch.nn.Linear(1500, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "        self.linear1 = Linear(50, 10)\n",
    "       \n",
    "\n",
    "        self.linear2 = Linear(1024,100)\n",
    "        self.linear3 = Linear(100, 25)\n",
    "        self.linear4 = Linear(25,10)\n",
    "        self.linear5 = Linear(20,  n_output)\n",
    "    def forward(self, data):\n",
    "        # graph input feed-forward\n",
    "        x, edge_index, batch, mol_feature = data.x, data.edge_index, data.batch, data.mol_feature\n",
    "        x = self.conv1(x.float(), edge_index)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.relu(x)\n",
    "        x = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "        x = self.fc_g1(self.dropout(x))\n",
    "        x = self.relu(x)\n",
    "        x = self.fc_g2(self.dropout(x))\n",
    "        x = self.relu(x)\n",
    "        x = self.linear1(self.dropout(x))\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        mol_feature=mol_feature.reshape(data.num_graphs,1024)\n",
    "        x1 = self.linear2(self.dropout(mol_feature.float()))\n",
    "        x1=F.relu(x1)\n",
    "        x1 = self.linear3(self.dropout(x1))\n",
    "        x1=F.relu(x1)\n",
    "        x1 = self.linear4(self.dropout(x1))\n",
    "        x1=F.relu(x1)\n",
    "        x = torch.cat([x, x1],dim=1)\n",
    "        out= torch.sigmoid(self.linear5(x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param ={}\n",
    "best_param[\"roc_epoch\"] = 0\n",
    "best_param[\"loss_epoch\"] = 0\n",
    "best_param[\"valid_roc\"] = 0\n",
    "best_param[\"valid_loss\"] = 9e8\n",
    "\n",
    "train_set = pd.read_csv('train_df.csv')\n",
    "valid_set = pd.read_csv('valid_df.csv')\n",
    "train_loader = data_process(train_set,100)\n",
    "valid_loader = data_process(valid_set,100)\n",
    "    \n",
    "model = FnGATGCN().float()\n",
    "model.apply(reset_weights)\n",
    "model.cuda()\n",
    "weight_decay = 3.0\n",
    "learning_rate = 3.5  \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=10**-learning_rate,weight_decay=10**-weight_decay)\n",
    "    \n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "test_auc = [] \n",
    "train_auc = [] \n",
    "for epoch in range(800):\n",
    "    train(epoch,train_loader)\n",
    "    test(epoch,valid_loader)\n",
    "    valid_roc = test_auc[-1]\n",
    "    valid_loss = test_loss[-1]\n",
    "    train_roc = train_auc[-1]\n",
    "    if valid_roc > best_param[\"valid_roc\"]:\n",
    "        best_param[\"roc_epoch\"] = epoch\n",
    "        best_param[\"valid_roc\"] = valid_roc\n",
    "        if valid_roc > 0.70:\n",
    "             torch.save(model, str(epoch)+'.pt')             \n",
    "    if valid_loss < best_param[\"valid_loss\"]:\n",
    "        best_param[\"loss_epoch\"] = epoch\n",
    "        best_param[\"valid_loss\"] = valid_loss\n",
    "\n",
    "    print(\"EPOCH:\\t\"+str(epoch)+'\\n'\\\n",
    "        +\"train_roc\"+\":\"+str(train_roc)+'\\n'\\\n",
    "        +\"valid_roc\"+\":\"+str(valid_roc)+'\\n'\\\n",
    "#         +\"train_roc_mean\"+\":\"+str(train_roc_mean)+'\\n'\\\n",
    "#         +\"valid_roc_mean\"+\":\"+str(valid_roc_mean)+'\\n'\\\n",
    "        )\n",
    "    if (epoch - best_param[\"roc_epoch\"] >18) and (epoch - best_param[\"loss_epoch\"] >28):        \n",
    "        break\n",
    "    \n",
    "model = torch.load(str(best_param[\"roc_epoch\"])+'.pt')\n",
    "auc, report = test_metrics(valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "model = torch.load(str(best_param[\"roc_epoch\"])+'.pt')     \n",
    "\n",
    "\n",
    "test_set = pd.read_csv('test_df.csv')\n",
    "test_loader = data_process(test_set,50)\n",
    "\n",
    "test_auc, report = test_metrics(test_loader)\n",
    "\n",
    "print(\"best epoch:\"+str(best_param[\"roc_epoch\"])\n",
    "      +\"\\n\"+\"test_roc:\"+str(test_auc)\n",
    "      +\"\\n\"+\"test_roc_mean:\",str(np.array(test_auc).mean())\n",
    "     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
